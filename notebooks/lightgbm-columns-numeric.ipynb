{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNzA5Rye4/ijILoyJ/ODjCO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_kqgicZOnt8V","executionInfo":{"status":"ok","timestamp":1679946864930,"user_tz":240,"elapsed":27473,"user":{"displayName":"Showndarya Madhavan","userId":"16229668428797306034"}},"outputId":"f448160f-49c6-4e5d-8b38-53043d6f3f94"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import MaxAbsScaler\n","from sklearn.pipeline import FeatureUnion\n","import lightgbm as lgb\n","from sklearn.linear_model import ElasticNet\n","\n","# Load the CSV file\n","df=pd.read_csv(\"drive/MyDrive/CS506-DS/midterm/data/train.csv\")\n","df=df.iloc[:30000]\n","print(df.keys())\n","\n","# Convert ReviewId column to int\n","df['Id'] = df['Id'].astype(int)\n","df['Summary'] = df['Summary'].astype(str)\n","df['Text'] = df['Text'].astype(str)\n","\n","# Define the TfidfVectorizer for character n-grams\n","char_vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(2, 4), max_features=5000)\n","\n","# Define the TfidfVectorizer for word n-grams\n","word_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), max_features=5000)\n","\n","# Combine the two vectorizers using FeatureUnion\n","vectorizer = FeatureUnion([\n","    ('char', char_vectorizer),\n","    ('word', word_vectorizer)\n","])\n","\n","# Apply the vectorizer to the Summary and Text columns\n","X_text = vectorizer.fit_transform(df[['Summary', 'Text']].apply(lambda x: ' '.join(x), axis=1)).toarray()\n","print(len(X_text))\n","\n","# Apply MaxAbsScaler to the feature matrix\n","scaler = MaxAbsScaler()\n","X_text_scaled = scaler.fit_transform(X_text)\n","\n","# Select the columns to be included in the model\n","df['HelpfulnessRatio'] = df['HelpfulnessNumerator'] / df['HelpfulnessDenominator']\n","X_other = df[['HelpfulnessRatio']].values\n","\n","# Apply MaxAbsScaler to the other feature matrix\n","X_other_scaled = scaler.fit_transform(X_other)\n","\n","# Concatenate the two feature matrices\n","X = np.concatenate((X_text_scaled, X_other_scaled), axis=1)\n","\n","# Convert all columns in X to numeric data types\n","X = X.astype(float)\n","\n","# Define the LightGBM model\n","model = ElasticNet(alpha=0.1, l1_ratio=0.5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j1jJsCaunwhm","outputId":"6c1b21ff-f676-4d34-feec-cb71b1e25674"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['Id', 'ProductId', 'UserId', 'HelpfulnessNumerator',\n","       'HelpfulnessDenominator', 'Time', 'Summary', 'Text', 'Score'],\n","      dtype='object')\n","35000\n"]}]},{"cell_type":"code","source":["X_submission = pd.read_csv(\"drive/MyDrive/CS506-DS/midterm/data/X_test.csv\")\n","# Select the columns to be included in the submission file\n","X_submission = X_submission[['Id', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Summary', 'Text']]\n","\n","# Create a new column for the helpfulness ratio\n","X_submission['HelpfulnessRatio'] = X_submission['HelpfulnessNumerator'] / X_submission['HelpfulnessDenominator']\n","\n","# Convert the Summary and Text columns to string data type\n","X_submission['Summary'] = X_submission['Summary'].astype(str)\n","X_submission['Text'] = X_submission['Text'].astype(str)\n","\n","# Fit the vectorizer on the test data\n","new_X_text = vectorizer.fit_transform(X_submission[['Summary', 'Text']].apply(lambda x: ' '.join(x), axis=1)).toarray()\n","\n","# Apply MaxAbsScaler to the new feature matrix\n","scaler_test = MaxAbsScaler()\n","new_X_text_scaled = scaler_test.fit_transform(new_X_text)\n","\n","# Apply the same scaler to the test data\n","X_submission_ratio_scaled = scaler.transform(X_submission[['HelpfulnessRatio']].values)\n","\n","# Concatenate the two feature matrices\n","new_X = np.concatenate((new_X_text_scaled, X_submission_ratio_scaled), axis=1)\n","\n","# Make predictions on the test data\n","X_submission['Score'] = model.predict(new_X, predict_disable_shape_check=True)\n","\n","# Select the columns to be included in the final submission file\n","submission = X_submission[['Id', 'Score']]\n","\n","# Save the submission file\n","submission.to_csv(\"submission.csv\", index=False)"],"metadata":{"id":"VAdDHnBdnw6D","executionInfo":{"status":"ok","timestamp":1679951189389,"user_tz":240,"elapsed":69220,"user":{"displayName":"Showndarya Madhavan","userId":"16229668428797306034"}}},"execution_count":3,"outputs":[]}]}