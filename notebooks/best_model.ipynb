{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5becbfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2327a688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Load the CSV file\n",
    "df=pd.read_csv(\"drive/MyDrive/CS506-DS/midterm/data/train.csv\")\n",
    "df=df.iloc[:60000]\n",
    "print(df.keys())\n",
    "\n",
    "# Convert ReviewId column to int\n",
    "df['Id'] = df['Id'].astype(int)\n",
    "df.drop(columns=[\"UserId\",\"Time\",\"Id\"], axis=1, inplace=True)\n",
    "df['Summary'] = df['Summary'].astype(str)\n",
    "df['Text'] = df['Text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d58fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Download the VADER lexicon if not already downloaded\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize the sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define a function to compute the sentiment scores for a given text\n",
    "def get_sentiment_scores(text):\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    return scores['neg'], scores['neu'], scores['pos'], scores['compound']\n",
    "\n",
    "# Apply the function to the 'Text' and 'Summary' columns\n",
    "df['Text_sentiment_neg'], df['Text_sentiment_neu'], df['Text_sentiment_pos'], df['Text_sentiment_compound'] = zip(*df['Text'].apply(get_sentiment_scores))\n",
    "df['Summary_sentiment_neg'], df['Summary_sentiment_neu'], df['Summary_sentiment_pos'], df['Summary_sentiment_compound'] = zip(*df['Summary'].apply(get_sentiment_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701de981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr_matrix = df[['Score', 'Text_sentiment_neg', 'Text_sentiment_neu', 'Text_sentiment_pos', 'Text_sentiment_compound', 'Summary_sentiment_neg', 'Summary_sentiment_neu', 'Summary_sentiment_pos', 'Summary_sentiment_compound']].corr()\n",
    "\n",
    "# Plot the correlation matrix as a heatmap\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix of Sentiment Scores and Review Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdac2073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import hstack\n",
    "import xgboost as xgb\n",
    "\n",
    "# Remove any rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert the Score column to a binary label\n",
    "threshold = 3\n",
    "df['label'] = (df['Score'] >= threshold).astype(int)\n",
    "\n",
    "# Shuffle the rows\n",
    "df = df.sample(frac=1, random_state=0)\n",
    "\n",
    "# Reset the index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=0)\n",
    "\n",
    "# Define the TfidfVectorizer for character n-grams\n",
    "char_vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(2, 4))\n",
    "\n",
    "# Define the TfidfVectorizer for word n-grams\n",
    "word_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 3))\n",
    "\n",
    "# Fit the vectorizers to the training data\n",
    "X_train_char = char_vectorizer.fit_transform(train_df['Summary'])\n",
    "X_train_word = word_vectorizer.fit_transform(train_df['Text'])\n",
    "\n",
    "# Transform the validation data using the fitted vectorizers\n",
    "X_val_char = char_vectorizer.transform(val_df['Summary'])\n",
    "X_val_word = word_vectorizer.transform(val_df['Text'])\n",
    "\n",
    "# Combine the TF-IDF features for training and validation data\n",
    "X_train_tfidf = hstack([X_train_char, X_train_word])\n",
    "X_val_tfidf = hstack([X_val_char, X_val_word])\n",
    "\n",
    "# Define the LightGBM model for TF-IDF features\n",
    "tfidf_params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'num_leaves': 30,\n",
    "    'learning_rate': 0.06,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1\n",
    "}\n",
    "tfidf_model = lgb.LGBMRegressor(**tfidf_params)\n",
    "\n",
    "# Train the model on the training data\n",
    "tfidf_model.fit(X_train_tfidf, train_df['Score'], eval_set=[(X_val_tfidf, val_df['Score'])], early_stopping_rounds=10, verbose=10)\n",
    "\n",
    "def extract_sentiment_features(df):\n",
    "    return df[['Summary_sentiment_compound', 'Text_sentiment_compound']].values\n",
    "\n",
    "# Define the feature union for sentiment features\n",
    "sentiment_union = FeatureUnion([\n",
    "    ('sentiment', FunctionTransformer(extract_sentiment_features, validate=False)),\n",
    "    ('helpfulness', MaxAbsScaler())\n",
    "])\n",
    "\n",
    "# Compute the helpfulness ratio\n",
    "df['HelpfulnessRatio'] = df['HelpfulnessNumerator'] / df['HelpfulnessDenominator']\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=0)\n",
    "\n",
    "# Fit the feature union to the training data\n",
    "X_train_sentiment = sentiment_union.fit_transform(train_df[['Summary_sentiment_compound', 'Text_sentiment_compound', 'HelpfulnessRatio']])\n",
    "X_val_sentiment = sentiment_union.transform(val_df[['Summary_sentiment_compound', 'Text_sentiment_compound', 'HelpfulnessRatio']])\n",
    "\n",
    "# Define the LightGBM model for sentiment features\n",
    "sentiment_params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'num_leaves': 30,\n",
    "    'learning_rate': 0.06,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1\n",
    "}\n",
    "sentiment_model = lgb.LGBMRegressor(**sentiment_params)\n",
    "# Train the model on the training data\n",
    "sentiment_model.fit(X_train_sentiment, train_df['Score'], eval_set=[(X_val_sentiment, val_df['Score'])], early_stopping_rounds=10, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c2d4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"drive/MyDrive/CS506-DS/midterm/data/X_test.csv\")\n",
    "test_df.drop(columns=[\"UserId\",\"Score\"], axis=1, inplace=True)\n",
    "\n",
    "test_df = test_df.dropna()\n",
    "\n",
    "# Shuffle the rows\n",
    "test_df = test_df.sample(frac=1, random_state=0)\n",
    "\n",
    "# Reset the index\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Apply the function to the 'Text' and 'Summary' columns\n",
    "test_df['Text_sentiment_neg'], test_df['Text_sentiment_neu'], test_df['Text_sentiment_pos'], test_df['Text_sentiment_compound'] = zip(*test_df['Text'].apply(get_sentiment_scores))\n",
    "test_df['Summary_sentiment_neg'], test_df['Summary_sentiment_neu'], test_df['Summary_sentiment_pos'], test_df['Summary_sentiment_compound'] = zip(*test_df['Summary'].apply(get_sentiment_scores))\n",
    "\n",
    "\n",
    "# Compute the helpfulness ratio\n",
    "test_df['HelpfulnessRatio'] = test_df['HelpfulnessNumerator'] / test_df['HelpfulnessDenominator']\n",
    "\n",
    "# Transform the test data using the fitted vectorizers\n",
    "X_test_char = char_vectorizer.transform(test_df['Summary'])\n",
    "X_test_word = word_vectorizer.transform(test_df['Text'])\n",
    "\n",
    "# Combine the TF-IDF features for test data\n",
    "X_test_tfidf = hstack([X_test_char, X_test_word])\n",
    "\n",
    "# Make predictions using the TF-IDF model\n",
    "tfidf_preds = tfidf_model.predict(X_test_tfidf)\n",
    "\n",
    "# Transform the test data using the feature union\n",
    "X_test_sentiment = sentiment_union.transform(test_df[['Summary_sentiment_compound', 'Text_sentiment_compound', 'HelpfulnessRatio']])\n",
    "\n",
    "# Make predictions using the sentiment model\n",
    "sentiment_preds = sentiment_model.predict(X_test_sentiment)\n",
    "\n",
    "# Combine the predictions from both models\n",
    "test_df['Score'] =  (0.65 * tfidf_preds) + (0.35 * sentiment_preds)\n",
    "\n",
    "\n",
    "submission = test_df[['Id', 'Score']]\n",
    "submission.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a816dcb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (377525354.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/8t/xtz7fzyn6_gg4jxvqj42whvh0000gn/T/ipykernel_67371/377525354.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    MULTICLASS SCORE (NOT THE BEST)\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "MULTICLASS SCORE (NOT THE BEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7bf93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer, MaxAbsScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import hstack\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Remove any rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert the Score column to a tertiary label\n",
    "df['label'] = pd.cut(df['Score'], bins=[0, 2, 4, 5], labels=['negative', 'neutral', 'positive'])\n",
    "\n",
    "# Shuffle the rows\n",
    "df = df.sample(frac=1, random_state=0)\n",
    "\n",
    "# Reset the index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=0)\n",
    "\n",
    "# Define the TfidfVectorizer for character n-grams\n",
    "char_vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(2, 4))\n",
    "\n",
    "# Define the TfidfVectorizer for word n-grams\n",
    "word_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 3))\n",
    "\n",
    "# Fit the vectorizers to the training data\n",
    "X_train_char = char_vectorizer.fit_transform(train_df['Summary'])\n",
    "X_train_word = word_vectorizer.fit_transform(train_df['Text'])\n",
    "\n",
    "# Transform the validation data using the fitted vectorizers\n",
    "X_val_char = char_vectorizer.transform(val_df['Summary'])\n",
    "X_val_word = word_vectorizer.transform(val_df['Text'])\n",
    "\n",
    "# Combine the TF-IDF features for training and validation data\n",
    "X_train_tfidf = hstack([X_train_char, X_train_word])\n",
    "X_val_tfidf = hstack([X_val_char, X_val_word])\n",
    "\n",
    "# Define the LightGBM model for TF-IDF features\n",
    "tfidf_params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 3,\n",
    "    'metric': 'multi_error',\n",
    "    'num_leaves': 30,\n",
    "    'learning_rate': 0.06,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1\n",
    "}\n",
    "tfidf_model = lgb.LGBMClassifier(**tfidf_params)\n",
    "\n",
    "# Train the model on the training data\n",
    "tfidf_model.fit(X_train_tfidf, train_df['label'], eval_set=[(X_val_tfidf, val_df['label'])], early_stopping_rounds=10, verbose=10)\n",
    "\n",
    "def extract_sentiment_features(df):\n",
    "    return df[['Summary_sentiment_compound', 'Text_sentiment_compound']].values\n",
    "    \n",
    "# Define the feature union for sentiment features\n",
    "sentiment_union = FeatureUnion([\n",
    "    ('sentiment', FunctionTransformer(extract_sentiment_features, validate=False)),\n",
    "    ('helpfulness', MaxAbsScaler())\n",
    "])\n",
    "\n",
    "# Compute the helpfulness ratio\n",
    "df['HelpfulnessRatio'] = df['HelpfulnessNumerator'] / df['HelpfulnessDenominator']\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=0)\n",
    "\n",
    "# Fit the feature union to the training data\n",
    "X_train_sentiment = sentiment_union.fit_transform(train_df[['Summary_sentiment_compound', 'Text_sentiment_compound', 'HelpfulnessRatio']])\n",
    "X_val_sentiment = sentiment_union.transform(val_df[['Summary_sentiment_compound', 'Text_sentiment_compound', 'HelpfulnessRatio']])\n",
    "\n",
    "# Define the LightGBM model for sentiment features\n",
    "sentiment_params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 3,\n",
    "    'metric': 'multi_error',\n",
    "    'num_leaves': 30,\n",
    "    'learning_rate': 0.06,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1\n",
    "}\n",
    "sentiment_model = lgb.LGBMClassifier(**sentiment_params)\n",
    "\n",
    "# Train the model on the training data\n",
    "sentiment_model.fit(X_train_sentiment, train_df['label'], eval_set=[(X_val_sentiment, val_df['label'])], early_stopping_rounds=10, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745b2bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_df = pd.read_csv(\"drive/MyDrive/CS506-DS/midterm/data/X_test.csv\")\n",
    "test_df.drop(columns=[\"ProductId\",\"UserId\",\"Score\"], axis=1, inplace=True)\n",
    "\n",
    "test_df = test_df.dropna()\n",
    "\n",
    "# Shuffle the rows\n",
    "test_df = test_df.sample(frac=1, random_state=0)\n",
    "\n",
    "# Reset the index\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Apply the function to the 'Text' and 'Summary' columns\n",
    "test_df['Text_sentiment_neg'], test_df['Text_sentiment_neu'], test_df['Text_sentiment_pos'], test_df['Text_sentiment_compound'] = zip(*test_df['Text'].apply(get_sentiment_scores))\n",
    "test_df['Summary_sentiment_neg'], test_df['Summary_sentiment_neu'], test_df['Summary_sentiment_pos'], test_df['Summary_sentiment_compound'] = zip(*test_df['Summary'].apply(get_sentiment_scores))\n",
    "\n",
    "\n",
    "# Compute the helpfulness ratio\n",
    "test_df['HelpfulnessRatio'] = test_df['HelpfulnessNumerator'] / test_df['HelpfulnessDenominator']\n",
    "\n",
    "# Transform the test data using the fitted vectorizers\n",
    "X_test_char = char_vectorizer.transform(test_df['Summary'])\n",
    "X_test_word = word_vectorizer.transform(test_df['Text'])\n",
    "\n",
    "# Combine the TF-IDF features for test data\n",
    "X_test_tfidf = hstack([X_test_char, X_test_word])\n",
    "\n",
    "# Make predictions using the TF-IDF model\n",
    "tfidf_preds = tfidf_model.predict(X_test_tfidf)\n",
    "\n",
    "# Transform the test data using the feature union\n",
    "X_test_sentiment = sentiment_union.transform(test_df[['Summary_sentiment_compound', 'Text_sentiment_compound', 'HelpfulnessRatio']])\n",
    "\n",
    "# Make predictions using the sentiment model\n",
    "sentiment_preds = sentiment_model.predict(X_test_sentiment)\n",
    "print(sentiment_preds)\n",
    "\n",
    "# map string labels to numerical values\n",
    "label_map = {'positive': 4, 'neutral': 2, 'negative': 0}\n",
    "\n",
    "# convert string labels to numerical values\n",
    "tfidf_preds_num = np.array([label_map[label] for label in tfidf_preds])\n",
    "sentiment_preds_num = np.array([label_map[label] for label in sentiment_preds])\n",
    "\n",
    "# Combine the predictions from both models\n",
    "test_df['Score'] =  (sentiment_preds_num + tfidf_preds_num) / 2\n",
    "\n",
    "submission = test_df[['Id', 'Score']]\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
