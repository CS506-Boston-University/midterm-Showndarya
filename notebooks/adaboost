{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNxI51U9YXXLr8Xpfd/raj/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m9MxE0PDfJO-","executionInfo":{"status":"ok","timestamp":1679692751222,"user_tz":240,"elapsed":17969,"user":{"displayName":"Showndarya Madhavan","userId":"16229668428797306034"}},"outputId":"65b48430-2371-4c92-8f9b-08a65de4e576"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YthGv2JrfG0i","outputId":"4c4737ae-1e82-4469-e82e-9dbba6f5207c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['Id', 'ProductId', 'UserId', 'HelpfulnessNumerator',\n","       'HelpfulnessDenominator', 'Time', 'Summary', 'Text', 'Score'],\n","      dtype='object')\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n"]}],"source":["import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import MaxAbsScaler\n","from sklearn.pipeline import FeatureUnion\n","from sklearn.ensemble import AdaBoostRegressor\n","from sklearn.tree import DecisionTreeRegressor\n","\n","# Load the CSV file\n","df=pd.read_csv(\"drive/MyDrive/CS506-DS/midterm/data/train.csv\")\n","df=df.sample(n=10000, random_state=42)\n","print(df.keys())\n","\n","# Convert ReviewId column to int\n","df['Id'] = df['Id'].astype(int)\n","df.drop(columns=[\"ProductId\",\"UserId\",\"Time\"], axis=1, inplace=True)\n","\n","df['Summary'] = df['Summary'].astype(str)\n","df['Text'] = df['Text'].astype(str)\n","\n","# Define the TfidfVectorizer for character n-grams\n","char_vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(2, 4))\n","\n","# Define the TfidfVectorizer for word n-grams\n","word_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 3))\n","\n","# Combine the two vectorizers using FeatureUnion\n","vectorizer = FeatureUnion([\n","    ('char', char_vectorizer),\n","    ('word', word_vectorizer)\n","])\n","\n","# Apply the vectorizer to the Summary and Text columns\n","X = vectorizer.fit_transform(df[['Summary', 'Text']].apply(lambda x: ' '.join(x), axis=1))\n","\n","# Apply MaxAbsScaler to the feature matrix\n","scaler = MaxAbsScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Define the AdaBoostRegressor model\n","base_estimator = DecisionTreeRegressor(max_depth=3)\n","model = AdaBoostRegressor(base_estimator=base_estimator, n_estimators=100, learning_rate=0.1, loss='square', random_state=42)\n","\n","# Train the model\n","model.fit(X_scaled, df['Score'])"]},{"cell_type":"code","source":["X_submission = pd.read_csv(\"drive/MyDrive/CS506-DS/midterm/data/X_test.csv\")\n","X_submission.drop(columns=[\"ProductId\",\"UserId\",\"Time\",\"Score\"], axis=1, inplace=True)\n","\n","X_submission['Summary'] = X_submission['Summary'].astype(str)\n","X_submission['Text'] = X_submission['Text'].astype(str)\n","\n","new_X=vectorizer.transform(X_submission['Summary'] + ' ' + X_submission['Text'])\n","new_X_scaled = scaler.transform(new_X)\n","\n","X_submission['Score'] = model.predict(new_X_scaled)\n","\n","submission = X_submission[['Id', 'Score']]\n","submission.to_csv(\"submission.csv\", index=False)"],"metadata":{"id":"aJXrBc4qfL5R"},"execution_count":null,"outputs":[]}]}